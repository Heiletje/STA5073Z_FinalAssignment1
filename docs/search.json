[
  {
    "objectID": "VZYHEI003.html",
    "href": "VZYHEI003.html",
    "title": "Prediction of Presidents",
    "section": "",
    "text": "Abstract\n\n\n\nIntroduction\n\n\n\nLiterature Review\n\n\n SONA \n Machine learning \n\nData\n\n\n Tokenization \n Pre-processing \n\nMethods\n\n\n Classification Tree (CT) \n Feed-forward Neural Network (NN) \n Convolutional Neural Network (CNN) \n Model performance metrics \n\nExploratory Data Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResults\n\n\n\nOverall model performance\n\n Accuracy \n F1-score \n\nOverall model performance\n\n\nDiscussion and Conclusion\n\n\n\nReferences"
  },
  {
    "objectID": "pycode.html",
    "href": "pycode.html",
    "title": "Prediction of Presidents",
    "section": "",
    "text": "Abstract\n\n\nConverging machine learning (ML) and natural language processing (NLP) techniques, a predictive text-analysis was performed on the State of the Nation Addresses (SONAs) delivered by South African presidents spanning the period from 1994 to 2023. Different types of neural networks (NNs) were employed for the purpose of predicting the president from their spoken sentences. Serving as a foundational-comparative model, a naive classification tree (CT) was first fitted followed by varying-in-complexity models from a simple feed-forward NN (FNN) to more sophisticated NNs, such as recurrent (RNN) and convolutional (CNN). For each predictive model, the involved text was transformed into features via three approaches, namely bag-of-words (BoW), term-frequency, inverse-document-frequency (tf-idf), and embeddings. A comparison, in terms of correct-classification capability, between the numerous NNs across the differently defined features was conducted with the objective of obtaining the optimal predictive model for the political speeches.\n\nIntroduction\n\n\nThe domains of machine learning (ML) and natural language processing (NLP) intersect at text-based analysis involving the underlying aim of prediction. In this instance, the text of interest to analyze are the annual State of the Nation Address (SONA) speeches (from 1994 to 2023), whilst the predictive objective is pointed at determining which one of the six different South African presidents (F.W. de Klerk, N.R. Mandela, T.M. Mbeki, K.P. Motlanthe, J.G. Zuma, and M.C. Ramaphosa) delivered some sentence contained therein.\nIn order to achieve this predictive analysis, diverse ML models with differing degrees of complexity are applied. First, in order to form a comparative basis for performance, a naïve classification tree is fitted. This is then followed with the implementation of three types of neural networks (NNs),each with ascending degrees of sophistication, specifically a simple one (feed-forward) and then more complex ones (recurrent and convolutional).\n\nLiterature Review\n\n\n SONA \nSONA, a pivotal event in the political programme of Parliament, serves as a presidential summary for the South African public. Specifically, the country’s current domestic affairs and international relations are reflected upon, past governmental work is perused, and future plans in terms of policies and civil projects are proposed. Through this address, accountability on the part of government is re-instilled and transparency with the public is re-affirmed on an annual basis, either once (non-election year) or twice (pre-and-post election) (Minister Faith Muthambi 2017).\n\nData\n\n\n Tokenization \nThe process of tokenization entails breaking up given text into units, referred to as tokens (or terms), which are meaningful for analysis (Zhang 2018). In this case, these tokens take on different structures, based on either a macro-context (i.e., sentences) or micro-context (i.e., words). At both scales, the way in which these tokens are valued will be varied. The value will either be defined by a bag-of-words (BoW) or term-frequency, inverse-document-frequency (tf-idf) approach. The former way implicates accounting for the number of occurrences of some token in some document. On the other hand, the latter way not only regards the frequency of some token, but also the significance thereof. Thus, tf-idf involves the assignment of some weight to each token in a document which in turn reflects its importance relative to the entire collection of documents (corpus). It then follows that the tf-idf value of a token t in a document d within a corpus D is calculated as the product of two constituents. The first being tf(t,d) defined as the quotient of the frequency of token t in document d and the total number of tokens in document d, whereas the second is idf(t, D) denoted by the quotient of the natural logarithm of the total number of documents in corpus D and the number of documents containing the token t (Silge and Robinson 2017).\n Pre-processing \n\nMethods\n\n\n Classification Tree (CT) \n\n\n\nFigure 1: Schematic representation of an exemplary CT.\n\n\nA classification tree (CT) (Breiman et al. 1984) is a straightforward ML technique predominately applied in categorical prediction contexts. This simple model operates on the principle of segmenting some data into subsets, where these partitions are based on distinct values of individual features. It is naïve in its approach given it considers each feature in isolation in order to make classifying decisions, hence often overlooking complex feature interactions.\nWhen applied to text-based data, a CT makes classification decisions based on either the frequency (a BoW representation) or weighted frequency of words (a tf-idf representation) as the features. As illustrated in Figure 1, each CT decision node (shown as a grey, rectangular block) represents a rule where some threshold on a particular word’s frequency (or weighted version thereof) is defined. While less conventional, word embeddings can also be utilized instead. Though, the CT is often found to be mediocre in its ability to fully exploit the rich semantic and syntactic relationships captured in embeddings. Given that embeddings provide a dense representation of words in a high-dimensional space, the simplistic decision boundaries of a CT are sub-par in capturing the associated contextual nuances (Charbuty and Mohsin Abdulazeez 2021).\nCT hyperparameters comprise of the minimum number of samples required to split a node as well as the maximum tree depth. Using a grid-search approach coupled with a k-fold cross-validation (CV) process, various combinations of these two hyperparameters over smaller sets of data (folds) are systematically assessed to find a configuration where a chosen performance metric is optimized. Here, such a metric is the average of evaluation scores (like accuracy) obtained across all folds for the hyperparameter set yielding the highest value thereof.\nCTs are superior in terms of its simplistic interpretability and visualization, though this advantage is tainted with its proneness to overfitting (with deep trees) and inability to capture feature complexity.\n Feed-forward Neural Network (NN) \n\n\n\nFigure 2: Schematic representation of an exemplary FNN\n\n\nA feed-forward Neural Network (FNN) is a type of artificial NN wherein connections between the nodes (neurons) do not form a cycle (uni-directional in nature). As depicted in Figure 2, this architecture is characterized by its stratified structure, comprising of an input layer (grey circles), one or more hidden layers (white circles), and an output layer (black circles). In each layer, the nodes apply weights and biases to inputs before passing through an activation function.\nIn text analysis, when using BoW or tf-idf representations, each word is represented as a feature (i.e., a unique input neuron). FNNs transform text-based data into numerical vectors where each dimension corresponds to a word frequency (or weighted version thereof). These vectors are efficiently processed, thereby enabling the network to learn patterns that are predictive of an outcome of interest (like predicting presidents from sentences). With the employment of embeddings, unlike CTs, FNNs are able to leverage such dense word representations to capture subtler semantic patterns, potentially leading to more enhanced predictions.\nFNN hyperparameters involve the number of hidden layers, the number of neurons in each hidden layer, the type of activation function (e.g., ReLU or tanh), and the learning rate. To identify the optimal network architecture, a grid search over these tuneable parameters is executed.\nIn contrast to CTs, FNNs possess a higher aptitude to deal with feature intricacies, whether there is high dimensionality or the presence of non-linear relationships. Despite this, FNNs are also still susceptible to overfitting (with many layers/nodes). Additionally, despite its ability to capture semantic information, this is hindered by its inherent incapacity to simultaneously encapsulate the sequential/temporal relationship prevalent in text.\n Convolutional Neural Network (CNN) \n\n\n\nFigure 3: Schematic representation of an exemplary CNN.\n\n\nConvolutional Neural Networks (CNNs), primarily applied within the field of image-processing, have also proven proficiency in processing natural language processing (NLP) tasks. CNNs are designed to adaptively learn spatial hierarchies of features from input data. In the context of text, this means the model is able to learn any recognizable patterns or sequences of words which carry significant semantic meaning.\nIn comparison to CTs and FNNS, CNNs are the most specialized to incorporate embeddings, exploiting the associated representation to capture contextual information. The convolutional layers (as shown in Figure 3) are able to detect local patterns (like phrases or commonly co-occurring words) within these embeddings. With this model, the BoW and tf-idf approach is not ordinarily applied, given that both these representations lack the inherent sequential nature of text. Thus, the ability of CNNs to capture local dependencies is limited.\nCNN hyperparameters consist of the number convolutional layers, the size and number of filters (kernels), the size of the pooling layers, and the dropout rate. To configure the optimal set of these tunable parameters, a grid search approach is applied.\nCNNs are able to capture local dependencies in text-based data, allowing for more apt short-length pattern recognition. However, when dealing with long-range dependencies (like with sentences), the performance of CNNs is dampened. Lastly, given the implicit shared-weight architecture of the model, the tendency to overfit is not as prevalent compared to CTs and FNNS.\n Recurrent Neural Network (RNN) \n\n\n\nFigure 4: Schematic representation of an exemplary RNN.\n\n\nRecurrent Neural Networks (RNNs) are designed to handle sequential data. This model shares a similar architecture to FNNs, as represented in Figure 4, with an exception of two differences. FNNs are uni-directional models, whilst RNNs are bi-directional in nature. For the latter model, this means that information from some nodes’ outputs are able to flow in a backward direction (represented as red arrows), affecting subsequent input to the same node. Moreover, RNNs share the same weight parameter within each layer unlike FNNs where different weights apply across each node.\nIn the context of text, this means RNNs are well-suited for tasks where understanding the order and context of words is paramount. Unlike FNNs, RNNs utilize internal state (memory) to process sequences of inputs, therefore allowing information across different parts of the text to be maintained.\nLike with CNNs, RNNs are more effective when employing embeddings in comparison to BoW or tf-idf representations. These latter two approaches do not preserve the sequential order of words, which is the key feature RNNs endeavour to exploit. Through embeddings, the model is able to understand context such as comprehending how the meaning of a word is contingent on its position. This is particularly pertinent in text-based analysis involving sentence structures.\nRNN hyperparameters, which can be optimized to values allowing for the best predictive model performance via a grid-search approach, include number of recurrent units and the size thereof, dropout rates, and types of recurrent layers.\nConversely to CNNs, RNNs are more capable of dealing with long-range dependencies prevalent in text-based data, given it implicitly depends on the existence of some sort of sequential element. Despite this, these models are rather difficult to train given exploding gradients (especially with long sequences like sentences), whilst also being expensive both in terms of intensity and time.\n Model performance metrics \n\nExploratory Data Analysis\n\n\nFigure 1\n\n\n\nFigure 5: Number of SONA speeches for each president.\n\n\nFigure 5 delineates the distribution of speeches across the different presidents, revealing a notable underrepresentation of de Klerk and Motlanthe. This scarcity of speeches, and so a shortage of number of sentences as well, amongst only two out of the six presidents results in an imbalanced corpus. The subsequent training of any ML model on such disproportionate data potentially jeopardizes the overall predictive performance and generalizability thereof. Consequently, it is strategically chosen to exclude de Klerk and Motlanthe, hence instead focusing the prediction task exclusively on Mbeki, Zuma (with ten speeches each), Mandela and Ramaphosa (with seven speeches each).\n\n\n\nFigure 6: Number of sentences in SONA speeches for each president.\n\n\nSubsequently, the number of sentences for this now stratified-by-presidents dataset is considered in Figure 6. Here, it is seen that although Mandela and Ramaphosa have the same number of speeches, the former president overall had the least number of sentences. Such a discrepancy between Mbeki and Zuma is less pronounced, though the latter president’s speech is nevertheless still marginally deemed as having more number of sentences than within Mbeki’ speeches. Overall, Mandela’s speeches can be deemed as the shortest, in contrast to Zuma and his longest speeches. Given this findings, there is an evident imbalance in the data which could implicate the implementation of the neural networks. Thus, to make it more consistent, a random sample of 1000 sentences from each president will be extracted for the building of the models.\n\n?@fig-avg_sentence_length illustrates a notable contrast in the textual characteristics of speeches by Mandela and Zuma. Although Mandela’s speeches encompass the fewest sentences, they surprisingly contain the second-highest average word count per sentence. Conversely, Zuma’s speeches, while having the highest sentence count, exhibit the shortest average sentence length.\n After balancing the data, undergoing word tokenization, and applying additional pre-processing steps (e.g., removal of stop words, other common words like greetings towards “madame” “speaker” and “honourable” “member”), the following most frequent fifteen words across all speeches are presented in ?@fig-top_words. Evidently, governing activities relating to different domains (from “economic” to “social”) are often mentioned.\n\n\n\nFigure 7: Most frequent words stated across all speeches, stratified by president.\n\n\nThen, the most frequent fifteen words now faceted by president is featured in Figure 7. From this, it seems as if Mandela uses more social-related diction with his common words being “society”, “public”, “people”. Whilst, the other three presidents’ vocabulary is more focused on economic-related jargon like “sector”, “economic”, “infrastructure”, “jobs”, “investment”, and “business”. Hence, there is concurrently differentiation between presidents (like Mandela from Ramaphosa), but also distinct likeness with the presence of overlapping words. This potentially foreshadows the challenge of classifying these presidential speeches due to such similarity.\n\n\nBest parameters (bow): {'max_depth': 7, 'min_samples_split': 10}\n\nClassification Report on Test Set (Classification Tree - bow):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0.33 |     0.03 |       0.05 |       321 |\n| Mbeki        |        0.56 |     0.08 |       0.15 |       480 |\n| Ramaphosa    |        0.62 |     0.1  |       0.17 |       456 |\n| Zuma         |        0.31 |     0.95 |       0.47 |       526 |\n| accuracy     |        0.33 |     0.33 |       0.33 |         0 |\n| macro avg    |        0.46 |     0.29 |       0.21 |      1783 |\n| weighted avg |        0.46 |     0.33 |       0.23 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n\n\n\n\n\n\n\n\n\n\nBest parameters (tfidf): {'max_depth': 7, 'min_samples_split': 10}\n\nClassification Report on Test Set (Classification Tree - tfidf):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0.35 |     0.02 |       0.04 |       321 |\n| Mbeki        |        0.52 |     0.09 |       0.15 |       480 |\n| Ramaphosa    |        0.6  |     0.1  |       0.17 |       456 |\n| Zuma         |        0.31 |     0.95 |       0.47 |       526 |\n| accuracy     |        0.33 |     0.33 |       0.33 |         0 |\n| macro avg    |        0.45 |     0.29 |       0.2  |      1783 |\n| weighted avg |        0.45 |     0.33 |       0.23 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n\n\n\n\n\n\n\n\n\n\nBest parameters (embedding): {'max_depth': 5, 'min_samples_split': 2}\n\nClassification Report on Test Set (Classification Tree - embedding):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0.21 |     0.07 |       0.11 |       321 |\n| Mbeki        |        0.29 |     0.81 |       0.43 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.34 |     0.22 |       0.26 |       526 |\n| accuracy     |        0.3  |     0.3  |       0.3  |         0 |\n| macro avg    |        0.21 |     0.27 |       0.2  |      1783 |\n| weighted avg |        0.22 |     0.3  |       0.21 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n\n\n\n\n\n\n\n\n\n\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n\n\n\nTraining model with (100,) hidden layers and relu activation\n 1/56 [..............................] - ETA: 4s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 503us/step\n\nClassification Report (bow - (100,) - relu):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0.28 |     0.19 |       0.23 |       321 |\n| Mbeki        |        0.43 |     0.36 |       0.39 |       480 |\n| Ramaphosa    |        0.44 |     0.4  |       0.42 |       456 |\n| Zuma         |        0.39 |     0.56 |       0.46 |       526 |\n| accuracy     |        0.4  |     0.4  |       0.4  |         0 |\n| macro avg    |        0.38 |     0.38 |       0.37 |      1783 |\n| weighted avg |        0.39 |     0.4  |       0.39 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n\nTraining model with (100,) hidden layers and tanh activation\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 467us/step\n\nClassification Report (bow - (100,) - tanh):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0.34 |     0.19 |       0.24 |       321 |\n| Mbeki        |        0.47 |     0.4  |       0.43 |       480 |\n| Ramaphosa    |        0.5  |     0.41 |       0.45 |       456 |\n| Zuma         |        0.4  |     0.62 |       0.49 |       526 |\n| accuracy     |        0.43 |     0.43 |       0.43 |         0 |\n| macro avg    |        0.43 |     0.41 |       0.4  |      1783 |\n| weighted avg |        0.43 |     0.43 |       0.42 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n\nTraining model with (100, 50) hidden layers and relu activation\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 408us/step\n\nClassification Report (bow - (100, 50) - relu):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0.3  |     0.21 |       0.24 |       321 |\n| Mbeki        |        0.45 |     0.41 |       0.43 |       480 |\n| Ramaphosa    |        0.48 |     0.4  |       0.44 |       456 |\n| Zuma         |        0.38 |     0.53 |       0.44 |       526 |\n| accuracy     |        0.41 |     0.41 |       0.41 |         0 |\n| macro avg    |        0.4  |     0.39 |       0.39 |      1783 |\n| weighted avg |        0.41 |     0.41 |       0.4  |      1783 |\n+--------------+-------------+----------+------------+-----------+\n\nTraining model with (100, 50) hidden layers and tanh activation\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 404us/step\n\nClassification Report (bow - (100, 50) - tanh):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0.32 |     0.21 |       0.26 |       321 |\n| Mbeki        |        0.44 |     0.38 |       0.41 |       480 |\n| Ramaphosa    |        0.41 |     0.37 |       0.39 |       456 |\n| Zuma         |        0.39 |     0.55 |       0.45 |       526 |\n| accuracy     |        0.4  |     0.4  |       0.4  |         0 |\n| macro avg    |        0.39 |     0.38 |       0.38 |      1783 |\n| weighted avg |        0.4  |     0.4  |       0.39 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n\n\n\nTraining model with (100,) hidden layers and relu activation\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 355us/step\n\nClassification Report (tf-idf - (100,) - relu):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0.32 |     0.2  |       0.25 |       321 |\n| Mbeki        |        0.47 |     0.38 |       0.42 |       480 |\n| Ramaphosa    |        0.48 |     0.43 |       0.45 |       456 |\n| Zuma         |        0.39 |     0.59 |       0.47 |       526 |\n| accuracy     |        0.42 |     0.42 |       0.42 |         0 |\n| macro avg    |        0.42 |     0.4  |       0.4  |      1783 |\n| weighted avg |        0.42 |     0.42 |       0.41 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n\nTraining model with (100,) hidden layers and tanh activation\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 362us/step\n\nClassification Report (tf-idf - (100,) - tanh):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0.36 |     0.18 |       0.24 |       321 |\n| Mbeki        |        0.47 |     0.44 |       0.45 |       480 |\n| Ramaphosa    |        0.46 |     0.41 |       0.43 |       456 |\n| Zuma         |        0.39 |     0.57 |       0.46 |       526 |\n| accuracy     |        0.42 |     0.42 |       0.42 |         0 |\n| macro avg    |        0.42 |     0.4  |       0.4  |      1783 |\n| weighted avg |        0.42 |     0.42 |       0.41 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n\nTraining model with (100, 50) hidden layers and relu activation\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 398us/step\n\nClassification Report (tf-idf - (100, 50) - relu):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0.31 |     0.17 |       0.22 |       321 |\n| Mbeki        |        0.46 |     0.39 |       0.42 |       480 |\n| Ramaphosa    |        0.47 |     0.41 |       0.44 |       456 |\n| Zuma         |        0.39 |     0.59 |       0.47 |       526 |\n| accuracy     |        0.42 |     0.42 |       0.42 |         0 |\n| macro avg    |        0.41 |     0.39 |       0.39 |      1783 |\n| weighted avg |        0.41 |     0.42 |       0.4  |      1783 |\n+--------------+-------------+----------+------------+-----------+\n\nTraining model with (100, 50) hidden layers and tanh activation\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 406us/step\n\nClassification Report (tf-idf - (100, 50) - tanh):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0.29 |     0.19 |       0.23 |       321 |\n| Mbeki        |        0.47 |     0.38 |       0.42 |       480 |\n| Ramaphosa    |        0.42 |     0.39 |       0.41 |       456 |\n| Zuma         |        0.39 |     0.56 |       0.46 |       526 |\n| accuracy     |        0.4  |     0.4  |       0.4  |         0 |\n| macro avg    |        0.39 |     0.38 |       0.38 |      1783 |\n| weighted avg |        0.4  |     0.4  |       0.39 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n\n\n\nTraining model with (100,) hidden layers and relu activation\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 381us/step\n\nClassification Report (embedding - (100,) - relu):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0    |     0    |       0    |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.3  |     1    |       0.46 |       526 |\n| accuracy     |        0.3  |     0.3  |       0.3  |         0 |\n| macro avg    |        0.07 |     0.25 |       0.11 |      1783 |\n| weighted avg |        0.09 |     0.3  |       0.13 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n\nTraining model with (100,) hidden layers and tanh activation\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 372us/step\n\nClassification Report (embedding - (100,) - tanh):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0    |     0    |       0    |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.3  |     1    |       0.46 |       526 |\n| accuracy     |        0.3  |     0.3  |       0.3  |         0 |\n| macro avg    |        0.07 |     0.25 |       0.11 |      1783 |\n| weighted avg |        0.09 |     0.3  |       0.13 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n\nTraining model with (100, 50) hidden layers and relu activation\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 390us/step\n\nClassification Report (embedding - (100, 50) - relu):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0.33 |     0.01 |       0.02 |       321 |\n| Mbeki        |        0.32 |     0.47 |       0.38 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.32 |     0.64 |       0.43 |       526 |\n| accuracy     |        0.32 |     0.32 |       0.32 |         0 |\n| macro avg    |        0.24 |     0.28 |       0.21 |      1783 |\n| weighted avg |        0.24 |     0.32 |       0.23 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n\nTraining model with (100, 50) hidden layers and tanh activation\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 383us/step\n\nClassification Report (embedding - (100, 50) - tanh):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.31 |     0.51 |       0.39 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.32 |     0.62 |       0.42 |       526 |\n| accuracy     |        0.32 |     0.32 |       0.32 |         0 |\n| macro avg    |        0.16 |     0.28 |       0.2  |      1783 |\n| weighted avg |        0.18 |     0.32 |       0.23 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n\n\nTraining model with filters=64, kernel_size=3, dropout_rate=0.2\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 596us/step\n\nClassification Report (CNN - BoW - Filters:64 Kernel:3 Dropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.37 |     0.21 |       0.27 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.31 |     0.9  |       0.46 |       526 |\n| accuracy     |        0.32 |     0.32 |       0.32 |         0 |\n| macro avg    |        0.17 |     0.28 |       0.18 |      1783 |\n| weighted avg |        0.19 |     0.32 |       0.21 |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=64, kernel_size=3, dropout_rate=0.5\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 586us/step\n\nClassification Report (CNN - BoW - Filters:64 Kernel:3 Dropout:0.5):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.37 |     0.21 |       0.27 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.31 |     0.9  |       0.46 |       526 |\n| accuracy     |        0.32 |     0.32 |       0.32 |         0 |\n| macro avg    |        0.17 |     0.28 |       0.18 |      1783 |\n| weighted avg |        0.19 |     0.32 |       0.21 |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=64, kernel_size=5, dropout_rate=0.2\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 552us/step\n\nClassification Report (CNN - BoW - Filters:64 Kernel:5 Dropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.37 |     0.29 |       0.32 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.32 |     0.85 |       0.46 |       526 |\n| accuracy     |        0.33 |     0.33 |       0.33 |         0 |\n| macro avg    |        0.17 |     0.28 |       0.2  |      1783 |\n| weighted avg |        0.19 |     0.33 |       0.22 |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=64, kernel_size=5, dropout_rate=0.5\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 579us/step\n\nClassification Report (CNN - BoW - Filters:64 Kernel:5 Dropout:0.5):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.37 |     0.29 |       0.32 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.32 |     0.85 |       0.46 |       526 |\n| accuracy     |        0.33 |     0.33 |       0.33 |         0 |\n| macro avg    |        0.17 |     0.28 |       0.2  |      1783 |\n| weighted avg |        0.19 |     0.33 |       0.22 |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=128, kernel_size=3, dropout_rate=0.2\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 710us/step\n\nClassification Report (CNN - BoW - Filters:128 Kernel:3 Dropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.37 |     0.21 |       0.27 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.31 |     0.9  |       0.46 |       526 |\n| accuracy     |        0.32 |     0.32 |       0.32 |         0 |\n| macro avg    |        0.17 |     0.28 |       0.18 |      1783 |\n| weighted avg |        0.19 |     0.32 |       0.21 |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=128, kernel_size=3, dropout_rate=0.5\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 688us/step\n\nClassification Report (CNN - BoW - Filters:128 Kernel:3 Dropout:0.5):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.37 |     0.21 |       0.27 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.31 |     0.9  |       0.46 |       526 |\n| accuracy     |        0.32 |     0.32 |       0.32 |         0 |\n| macro avg    |        0.17 |     0.28 |       0.18 |      1783 |\n| weighted avg |        0.19 |     0.32 |       0.21 |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=128, kernel_size=5, dropout_rate=0.2\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 719us/step\n\nClassification Report (CNN - BoW - Filters:128 Kernel:5 Dropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.37 |     0.29 |       0.32 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.32 |     0.85 |       0.46 |       526 |\n| accuracy     |        0.33 |     0.33 |       0.33 |         0 |\n| macro avg    |        0.17 |     0.28 |       0.2  |      1783 |\n| weighted avg |        0.19 |     0.33 |       0.22 |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=128, kernel_size=5, dropout_rate=0.5\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 716us/step\n\nClassification Report (CNN - BoW - Filters:128 Kernel:5 Dropout:0.5):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.37 |     0.29 |       0.32 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.32 |     0.85 |       0.46 |       526 |\n| accuracy     |        0.33 |     0.33 |       0.33 |         0 |\n| macro avg    |        0.17 |     0.28 |       0.2  |      1783 |\n| weighted avg |        0.19 |     0.33 |       0.22 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n+-----------+---------------+----------------+---------------------+\n|   Filters |   Kernel Size |   Dropout Rate |   Best Val Accuracy |\n|-----------+---------------+----------------+---------------------|\n|        64 |             5 |            0.5 |              0.3389 |\n|        64 |             5 |            0.2 |              0.3378 |\n|       128 |             5 |            0.2 |              0.3378 |\n|       128 |             5 |            0.5 |              0.3378 |\n|        64 |             3 |            0.2 |              0.3305 |\n|        64 |             3 |            0.5 |              0.3305 |\n|       128 |             3 |            0.2 |              0.3305 |\n|       128 |             3 |            0.5 |              0.3305 |\n+-----------+---------------+----------------+---------------------+\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraining model with filters=64, kernel_size=3, dropout_rate=0.2\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 558us/step\n\nClassification Report (CNN - tf-idf - Filters:64 Kernel:3 Dropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.34 |     0.51 |       0.41 |       480 |\n| Ramaphosa    |        1    |     0    |       0    |       456 |\n| Zuma         |        0.34 |     0.68 |       0.45 |       526 |\n| accuracy     |        0.34 |     0.34 |       0.34 |         0 |\n| macro avg    |        0.42 |     0.3  |       0.22 |      1783 |\n| weighted avg |        0.45 |     0.34 |       0.24 |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=64, kernel_size=3, dropout_rate=0.5\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 570us/step\n\nClassification Report (CNN - tf-idf - Filters:64 Kernel:3 Dropout:0.5):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.35 |     0.47 |       0.4  |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.33 |     0.72 |       0.46 |       526 |\n| accuracy     |        0.34 |     0.34 |       0.34 |         0 |\n| macro avg    |        0.17 |     0.3  |       0.21 |      1783 |\n| weighted avg |        0.19 |     0.34 |       0.24 |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=64, kernel_size=5, dropout_rate=0.2\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 582us/step\n\nClassification Report (CNN - tf-idf - Filters:64 Kernel:5 Dropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.34 |     0.5  |       0.4  |       480 |\n| Ramaphosa    |        0.5  |     0.01 |       0.02 |       456 |\n| Zuma         |        0.33 |     0.68 |       0.45 |       526 |\n| accuracy     |        0.34 |     0.34 |       0.34 |         0 |\n| macro avg    |        0.29 |     0.3  |       0.22 |      1783 |\n| weighted avg |        0.32 |     0.34 |       0.25 |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=64, kernel_size=5, dropout_rate=0.5\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 552us/step\n\nClassification Report (CNN - tf-idf - Filters:64 Kernel:5 Dropout:0.5):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.34 |     0.5  |       0.41 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.33 |     0.69 |       0.45 |       526 |\n| accuracy     |        0.34 |     0.34 |       0.34 |         0 |\n| macro avg    |        0.17 |     0.3  |       0.21 |      1783 |\n| weighted avg |        0.19 |     0.34 |       0.24 |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=128, kernel_size=3, dropout_rate=0.2\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 615us/step\n\nClassification Report (CNN - tf-idf - Filters:128 Kernel:3 Dropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.35 |     0.49 |       0.41 |       480 |\n| Ramaphosa    |        1    |     0    |       0    |       456 |\n| Zuma         |        0.33 |     0.7  |       0.45 |       526 |\n| accuracy     |        0.34 |     0.34 |       0.34 |         0 |\n| macro avg    |        0.42 |     0.3  |       0.21 |      1783 |\n| weighted avg |        0.45 |     0.34 |       0.24 |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=128, kernel_size=3, dropout_rate=0.5\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 652us/step\n\nClassification Report (CNN - tf-idf - Filters:128 Kernel:3 Dropout:0.5):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.34 |     0.53 |       0.42 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.34 |     0.67 |       0.45 |       526 |\n| accuracy     |        0.34 |     0.34 |       0.34 |         0 |\n| macro avg    |        0.17 |     0.3  |       0.22 |      1783 |\n| weighted avg |        0.19 |     0.34 |       0.25 |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=128, kernel_size=5, dropout_rate=0.2\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 666us/step\n\nClassification Report (CNN - tf-idf - Filters:128 Kernel:5 Dropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.35 |     0.47 |       0.4  |       480 |\n| Ramaphosa    |        0.75 |     0.01 |       0.01 |       456 |\n| Zuma         |        0.33 |     0.72 |       0.46 |       526 |\n| accuracy     |        0.34 |     0.34 |       0.34 |         0 |\n| macro avg    |        0.36 |     0.3  |       0.22 |      1783 |\n| weighted avg |        0.38 |     0.34 |       0.25 |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=128, kernel_size=5, dropout_rate=0.5\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 745us/step\n\nClassification Report (CNN - tf-idf - Filters:128 Kernel:5 Dropout:0.5):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.34 |     0.5  |       0.4  |       480 |\n| Ramaphosa    |        1    |     0    |       0    |       456 |\n| Zuma         |        0.34 |     0.69 |       0.45 |       526 |\n| accuracy     |        0.34 |     0.34 |       0.34 |         0 |\n| macro avg    |        0.42 |     0.3  |       0.22 |      1783 |\n| weighted avg |        0.45 |     0.34 |       0.24 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n+-----------+---------------+----------------+---------------------+\n|   Filters |   Kernel Size |   Dropout Rate |   Best Val Accuracy |\n|-----------+---------------+----------------+---------------------|\n|        64 |             3 |            0.2 |              0.3507 |\n|        64 |             3 |            0.5 |              0.3474 |\n|       128 |             3 |            0.2 |              0.3474 |\n|       128 |             3 |            0.5 |              0.3468 |\n|        64 |             5 |            0.5 |              0.3457 |\n|        64 |             5 |            0.2 |              0.3446 |\n|       128 |             5 |            0.5 |              0.3446 |\n|       128 |             5 |            0.2 |              0.3429 |\n+-----------+---------------+----------------+---------------------+\n\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraining model with filters=64, kernel_size=3, dropout_rate=0.2\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 578us/step\n\nClassification Report (CNN - Embedding - Filters:64 Kernel:3 Dropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.28 |     0.37 |       0.32 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.28 |     0.63 |       0.39 |       526 |\n| accuracy     |        0.28 |     0.28 |       0.28 |         0 |\n| macro avg    |        0.14 |     0.25 |       0.18 |      1783 |\n| weighted avg |        0.16 |     0.28 |       0.2  |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=64, kernel_size=3, dropout_rate=0.5\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 630us/step\n\nClassification Report (CNN - Embedding - Filters:64 Kernel:3 Dropout:0.5):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.26 |     0.17 |       0.21 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.28 |     0.78 |       0.42 |       526 |\n| accuracy     |        0.28 |     0.28 |       0.28 |         0 |\n| macro avg    |        0.13 |     0.24 |       0.16 |      1783 |\n| weighted avg |        0.15 |     0.28 |       0.18 |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=64, kernel_size=5, dropout_rate=0.2\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 629us/step\n\nClassification Report (CNN - Embedding - Filters:64 Kernel:5 Dropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.27 |     0.32 |       0.3  |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.28 |     0.65 |       0.39 |       526 |\n| accuracy     |        0.28 |     0.28 |       0.28 |         0 |\n| macro avg    |        0.14 |     0.24 |       0.17 |      1783 |\n| weighted avg |        0.16 |     0.28 |       0.2  |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=64, kernel_size=5, dropout_rate=0.5\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 593us/step\n\nClassification Report (CNN - Embedding - Filters:64 Kernel:5 Dropout:0.5):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.17 |     0.02 |       0.04 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.29 |     0.95 |       0.45 |       526 |\n| accuracy     |        0.29 |     0.29 |       0.29 |         0 |\n| macro avg    |        0.11 |     0.24 |       0.12 |      1783 |\n| weighted avg |        0.13 |     0.29 |       0.14 |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=128, kernel_size=3, dropout_rate=0.2\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 726us/step\n\nClassification Report (CNN - Embedding - Filters:128 Kernel:3 Dropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.28 |     0.28 |       0.28 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.28 |     0.71 |       0.4  |       526 |\n| accuracy     |        0.28 |     0.28 |       0.28 |         0 |\n| macro avg    |        0.14 |     0.25 |       0.17 |      1783 |\n| weighted avg |        0.16 |     0.28 |       0.19 |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=128, kernel_size=3, dropout_rate=0.5\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 726us/step\n\nClassification Report (CNN - Embedding - Filters:128 Kernel:3 Dropout:0.5):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.28 |     0.3  |       0.29 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.28 |     0.68 |       0.4  |       526 |\n| accuracy     |        0.28 |     0.28 |       0.28 |         0 |\n| macro avg    |        0.14 |     0.24 |       0.17 |      1783 |\n| weighted avg |        0.16 |     0.28 |       0.19 |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=128, kernel_size=5, dropout_rate=0.2\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 743us/step\n\nClassification Report (CNN - Embedding - Filters:128 Kernel:5 Dropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.28 |     0.28 |       0.28 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.28 |     0.7  |       0.4  |       526 |\n| accuracy     |        0.28 |     0.28 |       0.28 |         0 |\n| macro avg    |        0.14 |     0.25 |       0.17 |      1783 |\n| weighted avg |        0.16 |     0.28 |       0.19 |      1783 |\n+--------------+-------------+----------+------------+-----------+\nTraining model with filters=128, kernel_size=5, dropout_rate=0.5\n 1/56 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 717us/step\n\nClassification Report (CNN - Embedding - Filters:128 Kernel:5 Dropout:0.5):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.27 |     0.22 |       0.24 |       480 |\n| Ramaphosa    |        0    |     0    |       0    |       456 |\n| Zuma         |        0.28 |     0.74 |       0.41 |       526 |\n| accuracy     |        0.28 |     0.28 |       0.28 |         0 |\n| macro avg    |        0.14 |     0.24 |       0.16 |      1783 |\n| weighted avg |        0.16 |     0.28 |       0.19 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n+-----------+---------------+----------------+---------------------+\n|   Filters |   Kernel Size |   Dropout Rate |   Best Val Accuracy |\n|-----------+---------------+----------------+---------------------|\n|        64 |             5 |            0.2 |              0.307  |\n|        64 |             3 |            0.5 |              0.3047 |\n|       128 |             5 |            0.5 |              0.3047 |\n|       128 |             3 |            0.5 |              0.3042 |\n|        64 |             5 |            0.5 |              0.3036 |\n|       128 |             5 |            0.2 |              0.3036 |\n|       128 |             3 |            0.2 |              0.3025 |\n|        64 |             3 |            0.2 |              0.3013 |\n+-----------+---------------+----------------+---------------------+\n\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n\n\n\n\n\n 1/56 [..............................] - ETA: 6s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 8/56 [===&gt;..........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/56 [=======&gt;......................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b23/56 [===========&gt;..................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b31/56 [===============&gt;..............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b39/56 [===================&gt;..........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45/56 [=======================&gt;......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b50/56 [=========================&gt;....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 1s 8ms/step\n\nClassification Report (RNN - BoW - LSTM:50 SpatialDropout:0.0 Dropout:0.2 RecurrentDropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.41 |     0.34 |       0.37 |       480 |\n| Ramaphosa    |        0.64 |     0.02 |       0.03 |       456 |\n| Zuma         |        0.33 |     0.86 |       0.48 |       526 |\n| accuracy     |        0.35 |     0.35 |       0.35 |         0 |\n| macro avg    |        0.34 |     0.3  |       0.22 |      1783 |\n| weighted avg |        0.37 |     0.35 |       0.25 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n 1/56 [..............................] - ETA: 6s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 9/56 [===&gt;..........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b17/56 [========&gt;.....................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b25/56 [============&gt;.................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b33/56 [================&gt;.............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b41/56 [====================&gt;.........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b49/56 [=========================&gt;....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 7ms/step\n\nClassification Report (RNN - BoW - LSTM:50 SpatialDropout:0.2 Dropout:0.2 RecurrentDropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.56 |     0.03 |       0.06 |       480 |\n| Ramaphosa    |        0.43 |     0.01 |       0.03 |       456 |\n| Zuma         |        0.3  |     0.99 |       0.46 |       526 |\n| accuracy     |        0.3  |     0.3  |       0.3  |         0 |\n| macro avg    |        0.32 |     0.26 |       0.14 |      1783 |\n| weighted avg |        0.35 |     0.3  |       0.16 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n 1/56 [..............................] - ETA: 6s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 6/56 [==&gt;...........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b12/56 [=====&gt;........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b18/56 [========&gt;.....................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b24/56 [===========&gt;..................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b30/56 [===============&gt;..............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b36/56 [==================&gt;...........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b41/56 [====================&gt;.........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b47/56 [========================&gt;.....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b53/56 [===========================&gt;..] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 1s 10ms/step\n\nClassification Report (RNN - BoW - LSTM:75 SpatialDropout:0.0 Dropout:0.2 RecurrentDropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.4  |     0.11 |       0.17 |       480 |\n| Ramaphosa    |        0.5  |     0.01 |       0.03 |       456 |\n| Zuma         |        0.31 |     0.95 |       0.46 |       526 |\n| accuracy     |        0.31 |     0.31 |       0.31 |         0 |\n| macro avg    |        0.3  |     0.27 |       0.17 |      1783 |\n| weighted avg |        0.33 |     0.31 |       0.19 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n 1/56 [..............................] - ETA: 6s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 6/56 [==&gt;...........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b12/56 [=====&gt;........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b18/56 [========&gt;.....................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b24/56 [===========&gt;..................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b30/56 [===============&gt;..............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b36/56 [==================&gt;...........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b42/56 [=====================&gt;........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b48/56 [========================&gt;.....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b54/56 [===========================&gt;..] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 1s 10ms/step\n\nClassification Report (RNN - BoW - LSTM:75 SpatialDropout:0.2 Dropout:0.2 RecurrentDropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.45 |     0.08 |       0.14 |       480 |\n| Ramaphosa    |        0.43 |     0.01 |       0.03 |       456 |\n| Zuma         |        0.3  |     0.97 |       0.46 |       526 |\n| accuracy     |        0.31 |     0.31 |       0.31 |         0 |\n| macro avg    |        0.3  |     0.27 |       0.16 |      1783 |\n| weighted avg |        0.32 |     0.31 |       0.18 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n+--------------+-------------------+-----------+---------------------+---------------------+\n|   LSTM Units |   Spatial Dropout |   Dropout |   Recurrent Dropout |   Best Val Accuracy |\n|--------------+-------------------+-----------+---------------------+---------------------|\n|           50 |               0   |       0.2 |                 0.2 |              0.3625 |\n|           75 |               0   |       0.2 |                 0.2 |              0.3614 |\n|           50 |               0.2 |       0.2 |                 0.2 |              0.3378 |\n|           75 |               0.2 |       0.2 |                 0.2 |              0.3322 |\n+--------------+-------------------+-----------+---------------------+---------------------+\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nWARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/Users/heiletjevanzyl/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n\n\n\n\n\n 1/56 [..............................] - ETA: 6s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 8/56 [===&gt;..........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/56 [=======&gt;......................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b24/56 [===========&gt;..................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b32/56 [================&gt;.............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b40/56 [====================&gt;.........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b48/56 [========================&gt;.....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 7ms/step\n\nClassification Report (RNN - tf-idf - LSTM:50 SpatialDropout:0.0 Dropout:0.2 RecurrentDropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.31 |     0.14 |       0.19 |       480 |\n| Ramaphosa    |        0.53 |     0.02 |       0.04 |       456 |\n| Zuma         |        0.3  |     0.88 |       0.45 |       526 |\n| accuracy     |        0.3  |     0.3  |       0.3  |         0 |\n| macro avg    |        0.28 |     0.26 |       0.17 |      1783 |\n| weighted avg |        0.31 |     0.3  |       0.19 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n 1/56 [..............................] - ETA: 6s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 8/56 [===&gt;..........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16/56 [=======&gt;......................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b24/56 [===========&gt;..................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b32/56 [================&gt;.............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b40/56 [====================&gt;.........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b48/56 [========================&gt;.....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 0s 7ms/step\n\nClassification Report (RNN - tf-idf - LSTM:50 SpatialDropout:0.2 Dropout:0.2 RecurrentDropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.31 |     0.13 |       0.19 |       480 |\n| Ramaphosa    |        0.52 |     0.02 |       0.05 |       456 |\n| Zuma         |        0.3  |     0.9  |       0.45 |       526 |\n| accuracy     |        0.31 |     0.31 |       0.31 |         0 |\n| macro avg    |        0.28 |     0.26 |       0.17 |      1783 |\n| weighted avg |        0.31 |     0.31 |       0.2  |      1783 |\n+--------------+-------------+----------+------------+-----------+\n 1/56 [..............................] - ETA: 6s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 7/56 [==&gt;...........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b13/56 [=====&gt;........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b19/56 [=========&gt;....................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b25/56 [============&gt;.................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b31/56 [===============&gt;..............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b37/56 [==================&gt;...........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b43/56 [======================&gt;.......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b49/56 [=========================&gt;....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b55/56 [============================&gt;.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 1s 9ms/step\n\nClassification Report (RNN - tf-idf - LSTM:75 SpatialDropout:0.0 Dropout:0.2 RecurrentDropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.33 |     0.19 |       0.24 |       480 |\n| Ramaphosa    |        0.62 |     0.04 |       0.07 |       456 |\n| Zuma         |        0.3  |     0.85 |       0.45 |       526 |\n| accuracy     |        0.31 |     0.31 |       0.31 |         0 |\n| macro avg    |        0.31 |     0.27 |       0.19 |      1783 |\n| weighted avg |        0.34 |     0.31 |       0.22 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n 1/56 [..............................] - ETA: 6s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 6/56 [==&gt;...........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b12/56 [=====&gt;........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b18/56 [========&gt;.....................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b24/56 [===========&gt;..................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b30/56 [===============&gt;..............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b36/56 [==================&gt;...........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b42/56 [=====================&gt;........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b48/56 [========================&gt;.....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b54/56 [===========================&gt;..] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b56/56 [==============================] - 1s 9ms/step\n\nClassification Report (RNN - tf-idf - LSTM:75 SpatialDropout:0.2 Dropout:0.2 RecurrentDropout:0.2):\n+--------------+-------------+----------+------------+-----------+\n|              |   precision |   recall |   f1-score |   support |\n|--------------+-------------+----------+------------+-----------|\n| Mandela      |        0    |     0    |       0    |       321 |\n| Mbeki        |        0.31 |     0.14 |       0.19 |       480 |\n| Ramaphosa    |        0.6  |     0.05 |       0.09 |       456 |\n| Zuma         |        0.3  |     0.88 |       0.45 |       526 |\n| accuracy     |        0.31 |     0.31 |       0.31 |         0 |\n| macro avg    |        0.3  |     0.27 |       0.18 |      1783 |\n| weighted avg |        0.33 |     0.31 |       0.21 |      1783 |\n+--------------+-------------+----------+------------+-----------+\n+--------------+-------------------+-----------+---------------------+---------------------+\n|   LSTM Units |   Spatial Dropout |   Dropout |   Recurrent Dropout |   Best Val Accuracy |\n|--------------+-------------------+-----------+---------------------+---------------------|\n|           50 |               0.2 |       0.2 |                 0.2 |              0.3395 |\n|           75 |               0   |       0.2 |                 0.2 |              0.3215 |\n|           75 |               0.2 |       0.2 |                 0.2 |              0.3154 |\n|           50 |               0   |       0.2 |                 0.2 |              0.3143 |\n+--------------+-------------------+-----------+---------------------+---------------------+\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscussion and Conclusion\n\n\nUpon examination of the test-set accuracy for all Presidents, it is observed that the Bag of Words (BoW) and Term Frequency-Inverse Document Frequency (tf-idf) methods demonstrate a higher accuracy rate of 33%, whereas the embedding approach exhibits a marginally lower accuracy of 29%. This pattern is consistent in the validation-set, with negligible variation in accuracy percentages. Notably, the F1-score remains modest across all methods, averaging around 0.2.\nIn the context of CT employing the BoW method, it is noteworthy that President Zuma’s sentences were most accurately classified, with a total of 500 sentences correctly identified. Similarly, when utilizing the CT with tf-idf method, this heightened predictive performance is exclusively apparent for President Zuma. In stark contrast, the predictive accuracy for sentences of other Presidents is remarkably low, with values below 50.\nThe FNN model that incorporates a Bag of Words (BoW) framework with a ReLU activation function registers a testing accuracy of 40% and an F1-score of 0.37. In comparison, an enhancement is observed in the BoW-FNN model employing a tanh activation function, which achieves a testing accuracy of 43% and an F1-score of 0.4. These metrics are consistent with the trends noted in the training accuracy and F1-scores.\nWhen evaluating models that utilize embedding techniques, a general trend of reduced testing accuracy is apparent, hovering around the 30% mark. This suggests a relative underperformance of embedding models compared to their BoW-FNN counterparts.\nFurther analysis reveals that both the ReLU and tanh activation functions in the validation dataset are associated with suboptimal performance, characterized by an uptick in loss and a downtrend in accuracy. However, an exception is noted in the BoW-FNN model with the tanh activation, where the loss function values exhibit a tendency to stabilize, indicating a more robust model performance under these specific parameters.\nAn examination of the embedding models’ loss function plots shows a consistent decrease, yet they do not necessarily signal convergence, as evidenced by the absence of a leveling off. This lack of convergence suggests that these models might benefit from additional training epochs to potentially enhance their predictive accuracy.\nDiving deeper into the predictive capabilities of various models, the confusion matrices for some embedding models unveil a varied performance based on the activation function. Specifically, the ReLU activation fails to correctly classify sentences by Mandela and Ramaphosa. In stark contrast, the embedding model with tanh activation and configured with (100, 50) hidden layers demonstrates a notably better predictive capacity for sentences by Mbeki and Zuma.\nIn an overarching assessment, FNN models emerge as more adept at classifying the speeches of various presidents compared to other models. This superior classification capability is exemplified in the accurate prediction of Zuma’s sentences across all FNN models, irrespective of the approach or activation function. This trend aligns with the findings from the CT. Furthermore, the BoW and tf-idf FNN models display a more diversified classification ability across different presidents, extending beyond Zuma. However, a persistent challenge remains in accurately predicting Mandela’s sentences, which are consistently the least accurately classified across the models.\n\nReferences\n\n\n\n\n\n\n\nReferences\n\nBreiman, Leo, J. H. Friedman, R. A. Olshen, and C. J. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth & Brooks/Cole Advanced Books & Software.\n\n\nCharbuty, Bahzad, and Adnan Mohsin Abdulazeez. 2021. “Classification Based on Decision Tree Algorithm for Machine Learning.” Journal of Applied Science and Technology Trends 2 (March): 20–28. https://doi.org/10.38094/jastt20165.\n\n\nMinister Faith Muthambi. 2017. “SONA enables us to take part in our democracy.” 2017. https://www.gcis.gov.za/sona-enables-us-take-part-our-democracy.\n\n\nSilge, Julia, and David Robinson. 2017. Text Mining with R: A Tidy Approach. 1st ed. O’Reilly Media, Inc.\n\n\nZhang, Zhiyong. 2018. “Text Mining for Social and Behavioral Research using R.” 2018. https://books.psychstat.org/textmining/index.html."
  },
  {
    "objectID": "model_results/index.html",
    "href": "model_results/index.html",
    "title": "STA5073Z Data Science for Industry Assignment 2",
    "section": "",
    "text": "This is the website for the second assignment (pertaining to sentiment analysis and topic modelling) of the Masters-level course “Data Science for Industry” (DS4I) at the University of Cape Town. All relevant files related to this assignment are archived here."
  },
  {
    "objectID": "code_appendix.html",
    "href": "code_appendix.html",
    "title": "Code",
    "section": "",
    "text": "Data pre-processing\n\n\n\nExploratory data analysis\n\n\n\nTraining, validation, testing splits\n\n\n\nFeature creation\n\n\n\nClassification trees\n\n\n\nFeed-forward Neural Network\n\n\n\nRecurrent Neural Network\n\n\n\nConvolutional Neural Network"
  },
  {
    "objectID": "plaigarism_declaration.html",
    "href": "plaigarism_declaration.html",
    "title": "Plaigarism Declaration",
    "section": "",
    "text": "I, Heiletjé van Zyl, declare that this first DS4I assignment titled, “Prediction of Presidents” and the work presented in it is my own. I confirm that:\n\nThis work was done wholly while in candidature as an accredited course to obtain a degree at this University.\nThe contents of this assignment has not been previously submitted for a degree or any other qualification at this University or any other institution.\nWhere I have consulted the published work of others, this is always clearly attributed.\nWhere I have quoted from the work of others, the source is always given. With the exception of such quotations, this assignment is entirely my own work.\nI have acknowledged all main sources of help.\n\nSignature: HMMvZ\nDate: 17 November 2023"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA5073Z Data Science for Industry Assignment 1",
    "section": "",
    "text": "This is the website for the first assignment (pertaining to neural networks) of the Masters-level course “Data Science for Industry” (DS4I) at the University of Cape Town. All relevant files related to this assignment are archived here."
  }
]