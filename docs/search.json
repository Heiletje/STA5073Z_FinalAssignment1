[
  {
    "objectID": "VZYHEI003.html",
    "href": "VZYHEI003.html",
    "title": "Prediction of Presidents",
    "section": "",
    "text": "Abstract\n\n\n\nIntroduction\n\n\n\nLiterature Review\n\n\n SONA \n Machine learning \n\nData\n\n\n Tokenization \n Pre-processing \n\nMethods\n\n\n Classification Tree (CT) \n Feed-forward Neural Network (NN) \n Convolutional Neural Network (CNN) \n Model performance metrics \n\nExploratory Data Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResults\n\n\n\nOverall model performance\n\n Accuracy \n F1-score \n\nOverall model performance\n\n\nDiscussion and Conclusion\n\n\n\nReferences"
  },
  {
    "objectID": "pycode.html",
    "href": "pycode.html",
    "title": "Prediction of Presidents",
    "section": "",
    "text": "Abstract\n\n\nConverging machine learning (ML) and natural language processing (NLP) techniques, a predictive text-analysis was performed on the State of the Nation Addresses (SONAs) delivered by South African presidents spanning the period from 1994 to 2023. Different types of neural networks (NNs) were employed for the purpose of predicting the president from their spoken sentences. Serving as a foundational-comparative model, a naive classification tree (CT) was first fitted followed by varying-in-complexity models from a simple feed-forward NN (FNN) to more sophisticated NNs, such as recurrent (RNN) and convolutional (CNN). For each predictive model, the involved text was transformed into features via three approaches, namely bag-of-words (BoW), term-frequency, inverse-document-frequency (tf-idf), and embeddings. A comparison, in terms of correct-classification capability, between the numerous NNs across the differently defined features was conducted with the objective of obtaining the optimal predictive model for the political speeches.\n\nIntroduction\n\n\nThe domains of machine learning (ML) and natural language processing (NLP) intersect at text-based analysis involving the underlying aim of prediction. In this instance, the text of interest to analyze are the annual State of the Nation Address (SONA) speeches (from 1994 to 2023), whilst the predictive objective is pointed at determining which one of the six different South African presidents (F.W. de Klerk, N.R. Mandela, T.M. Mbeki, K.P. Motlanthe, J.G. Zuma, and M.C. Ramaphosa) delivered some sentence contained therein.\nIn order to achieve this predictive analysis, diverse ML models with differing degrees of complexity are applied. First, in order to form a comparative basis for performance, a naïve classification tree is fitted. This is then followed with the implementation of three types of neural networks (NNs),each with ascending degrees of sophistication, specifically a simple one (feed-forward) and then more complex ones (recurrent and convolutional).\n\nLiterature Review\n\n\n SONA \nSONA, a pivotal event in the political programme of Parliament, serves as a presidential summary for the South African public. Specifically, the country’s current domestic affairs and international relations are reflected upon, past governmental work is perused, and future plans in terms of policies and civil projects are proposed. Through this address, accountability on the part of government is re-instilled and transparency with the public is re-affirmed on an annual basis, either once (non-election year) or twice (pre-and-post election) (Minister Faith Muthambi 2017).\n\nData\n\n\n Tokenization \nThe process of tokenization entails breaking up given text into units, referred to as tokens (or terms), which are meaningful for analysis (Zhang 2018). In this case, these tokens take on different structures, based on either a macro-context (i.e., sentences) or micro-context (i.e., words). At both scales, the way in which these tokens are valued will be varied. The value will either be defined by a bag-of-words (BoW) or term-frequency, inverse-document-frequency (tf-idf) approach. The former way implicates accounting for the number of occurrences of some token in some document. On the other hand, the latter way not only regards the frequency of some token, but also the significance thereof. Thus, tf-idf involves the assignment of some weight to each token in a document which in turn reflects its importance relative to the entire collection of documents (corpus). It then follows that the tf-idf value of a token t in a document d within a corpus D is calculated as the product of two constituents. The first being tf(t,d) defined as the quotient of the frequency of token t in document d and the total number of tokens in document d, whereas the second is idf(t, D) denoted by the quotient of the natural logarithm of the total number of documents in corpus D and the number of documents containing the token t (Silge and Robinson 2017).\n Pre-processing \n\nMethods\n\n\n Classification Tree (CT) \n\n\n\nFigure 1: Schematic representation of an exemplary CT.\n\n\nA classification tree (CT) (Breiman et al. 1984) is a straightforward ML technique predominately applied in categorical prediction contexts. This simple model operates on the principle of segmenting some data into subsets, where these partitions are based on distinct values of individual features. It is naïve in its approach given it considers each feature in isolation in order to make classifying decisions, hence often overlooking complex feature interactions.\nWhen applied to text-based data, a CT makes classification decisions based on either the frequency (a BoW representation) or weighted frequency of words (a tf-idf representation) as the features. As illustrated in Figure 1, each CT decision node (shown as a grey, rectangular block) represents a rule where some threshold on a particular word’s frequency (or weighted version thereof) is defined. While less conventional, word embeddings can also be utilized instead. Though, the CT is often found to be mediocre in its ability to fully exploit the rich semantic and syntactic relationships captured in embeddings. Given that embeddings provide a dense representation of words in a high-dimensional space, the simplistic decision boundaries of a CT are sub-par in capturing the associated contextual nuances (Charbuty and Mohsin Abdulazeez 2021).\nCT hyperparameters comprise of the minimum number of samples required to split a node as well as the maximum tree depth. Using a grid-search approach coupled with a k-fold cross-validation (CV) process, various combinations of these two hyperparameters over smaller sets of data (folds) are systematically assessed to find a configuration where a chosen performance metric is optimized. Here, such a metric is the average of evaluation scores (like accuracy) obtained across all folds for the hyperparameter set yielding the highest value thereof.\nCTs are superior in terms of its simplistic interpretability and visualization, though this advantage is tainted with its proneness to overfitting (with deep trees) and inability to capture feature complexity.\n Feed-forward Neural Network (NN) \n\n\n\nFigure 2: Schematic representation of an exemplary FNN\n\n\nA feed-forward Neural Network (FNN) is a type of artificial NN wherein connections between the nodes (neurons) do not form a cycle (uni-directional in nature). As depicted in Figure 2, this architecture is characterized by its stratified structure, comprising of an input layer (grey circles), one or more hidden layers (white circles), and an output layer (black circles). In each layer, the nodes apply weights and biases to inputs before passing through an activation function.\nIn text analysis, when using BoW or tf-idf representations, each word is represented as a feature (i.e., a unique input neuron). FNNs transform text-based data into numerical vectors where each dimension corresponds to a word frequency (or weighted version thereof). These vectors are efficiently processed, thereby enabling the network to learn patterns that are predictive of an outcome of interest (like predicting presidents from sentences). With the employment of embeddings, unlike CTs, FNNs are able to leverage such dense word representations to capture subtler semantic patterns, potentially leading to more enhanced predictions.\nFNN hyperparameters involve the number of hidden layers, the number of neurons in each hidden layer, the type of activation function (e.g., ReLU or tanh), and the learning rate. To identify the optimal network architecture, a grid search over these tuneable parameters is executed.\nIn contrast to CTs, FNNs possess a higher aptitude to deal with feature intricacies, whether there is high dimensionality or the presence of non-linear relationships. Despite this, FNNs are also still susceptible to overfitting (with many layers/nodes). Additionally, despite its ability to capture semantic information, this is hindered by its inherent incapacity to simultaneously encapsulate the sequential/temporal relationship prevalent in text.\n Convolutional Neural Network (CNN) \n\n\n\nFigure 3: Schematic representation of an exemplary CNN.\n\n\nConvolutional Neural Networks (CNNs), primarily applied within the field of image-processing, have also proven proficiency in processing natural language processing (NLP) tasks. CNNs are designed to adaptively learn spatial hierarchies of features from input data. In the context of text, this means the model is able to learn any recognizable patterns or sequences of words which carry significant semantic meaning.\nIn comparison to CTs and FNNS, CNNs are the most specialized to incorporate embeddings, exploiting the associated representation to capture contextual information. The convolutional layers (as shown in Figure 3) are able to detect local patterns (like phrases or commonly co-occurring words) within these embeddings. With this model, the BoW and tf-idf approach is not ordinarily applied, given that both these representations lack the inherent sequential nature of text. Thus, the ability of CNNs to capture local dependencies is limited.\nCNN hyperparameters consist of the number convolutional layers, the size and number of filters (kernels), the size of the pooling layers, and the dropout rate. To configure the optimal set of these tunable parameters, a grid search approach is applied.\nCNNs are able to capture local dependencies in text-based data, allowing for more apt short-length pattern recognition. However, when dealing with long-range dependencies (like with sentences), the performance of CNNs is dampened. Lastly, given the implicit shared-weight architecture of the model, the tendency to overfit is not as prevalent compared to CTs and FNNS.\n Recurrent Neural Network (RNN) \n\n\n\nFigure 4: Schematic representation of an exemplary RNN.\n\n\nRecurrent Neural Networks (RNNs) are designed to handle sequential data. This model shares a similar architecture to FNNs, as represented in Figure 4, with an exception of two differences. FNNs are uni-directional models, whilst RNNs are bi-directional in nature. For the latter model, this means that information from some nodes’ outputs are able to flow in a backward direction (represented as red arrows), affecting subsequent input to the same node. Moreover, RNNs share the same weight parameter within each layer unlike FNNs where different weights apply across each node.\nIn the context of text, this means RNNs are well-suited for tasks where understanding the order and context of words is paramount. Unlike FNNs, RNNs utilize internal state (memory) to process sequences of inputs, therefore allowing information across different parts of the text to be maintained.\nLike with CNNs, RNNs are more effective when employing embeddings in comparison to BoW or tf-idf representations. These latter two approaches do not preserve the sequential order of words, which is the key feature RNNs endeavour to exploit. Through embeddings, the model is able to understand context such as comprehending how the meaning of a word is contingent on its position. This is particularly pertinent in text-based analysis involving sentence structures.\nRNN hyperparameters, which can be optimized to values allowing for the best predictive model performance via a grid-search approach, include number of recurrent units and the size thereof, dropout rates, and types of recurrent layers.\nConversely to CNNs, RNNs are more capable of dealing with long-range dependencies prevalent in text-based data, given it implicitly depends on the existence of some sort of sequential element. Despite this, these models are rather difficult to train given exploding gradients (especially with long sequences like sentences), whilst also being expensive both in terms of intensity and time.\n Model performance metrics \n\nExploratory Data Analysis\n\n\nFigure 1\n\n?@fig-president_num_speeches delineates the distribution of speeches across the different presidents, revealing a notable underrepresentation of de Klerk and Motlanthe. This scarcity of speeches, and so a shortage of number of sentences as well, amongst only two out of the six presidents results in an imbalanced corpus. The subsequent training of any ML model on such disproportionate data potentially jeopardizes the overall predictive performance and generalizability thereof. Consequently, it is strategically chosen to exclude de Klerk and Motlanthe, hence instead focusing the prediction task exclusively on Mbeki, Zuma (with ten speeches each), Mandela and Ramaphosa (with seven speeches each).\n\n\n\nFigure 5: Number of sentences in SONA speeches for each president.\n\n\nFigure 5\n\n?@fig-avg_sentence_length illustrates a notable contrast in the textual characteristics of speeches by Mandela and Zuma. Although Mandela’s speeches encompass the fewest sentences, they surprisingly contain the second-highest average word count per sentence. Conversely, Zuma’s speeches, while having the highest sentence count, exhibit the shortest average sentence length.\n ?@fig-top_words\n ?@fig-top_words_per_president\n\n\n\n\n\nReferences\n\nBreiman, Leo, J. H. Friedman, R. A. Olshen, and C. J. Stone. 1984. Classification and Regression Trees. Monterey, CA: Wadsworth & Brooks/Cole Advanced Books & Software.\n\n\nCharbuty, Bahzad, and Adnan Mohsin Abdulazeez. 2021. “Classification Based on Decision Tree Algorithm for Machine Learning.” Journal of Applied Science and Technology Trends 2 (March): 20–28. https://doi.org/10.38094/jastt20165.\n\n\nMinister Faith Muthambi. 2017. “SONA enables us to take part in our democracy.” 2017. https://www.gcis.gov.za/sona-enables-us-take-part-our-democracy.\n\n\nSilge, Julia, and David Robinson. 2017. Text Mining with R: A Tidy Approach. 1st ed. O’Reilly Media, Inc.\n\n\nZhang, Zhiyong. 2018. “Text Mining for Social and Behavioral Research using R.” 2018. https://books.psychstat.org/textmining/index.html."
  },
  {
    "objectID": "model_results/index.html",
    "href": "model_results/index.html",
    "title": "STA5073Z Data Science for Industry Assignment 2",
    "section": "",
    "text": "This is the website for the second assignment (pertaining to sentiment analysis and topic modelling) of the Masters-level course “Data Science for Industry” (DS4I) at the University of Cape Town. All relevant files related to this assignment are archived here."
  },
  {
    "objectID": "code_appendix.html",
    "href": "code_appendix.html",
    "title": "Code",
    "section": "",
    "text": "Data pre-processing\n\n\n\nExploratory data analysis\n\n\n\nTraining, validation, testing splits\n\n\n\nFeature creation\n\n\n\nClassification trees\n\n\n\nFeed-forward Neural Network\n\n\n\nRecurrent Neural Network\n\n\n\nConvolutional Neural Network"
  },
  {
    "objectID": "plaigarism_declaration.html",
    "href": "plaigarism_declaration.html",
    "title": "Plaigarism Declaration",
    "section": "",
    "text": "I, Heiletjé van Zyl, declare that this first DS4I assignment titled, “Prediction of Presidents” and the work presented in it is my own. I confirm that:\n\nThis work was done wholly while in candidature as an accredited course to obtain a degree at this University.\nThe contents of this assignment has not been previously submitted for a degree or any other qualification at this University or any other institution.\nWhere I have consulted the published work of others, this is always clearly attributed.\nWhere I have quoted from the work of others, the source is always given. With the exception of such quotations, this assignment is entirely my own work.\nI have acknowledged all main sources of help.\n\nSignature: HMMvZ\nDate: 17 November 2023"
  }
]